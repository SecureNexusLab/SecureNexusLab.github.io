---
layout: page
title: 字节ByteAI安全挑战赛——完赛告捷！
author: SecureNexusLab
cover: true
sidebar: []
readmore: true
date: 2024-10-29
tags: 
- 公众号推文
categories:
- 公众号推文
---

团队比赛总结  

**CTF  TRAVEL:**

团队在参与了本次ByteAI安全挑战赛，在初赛中，从三百多支战队中，成功的晋级了前十名！

![](/images/字节ByteAI安全挑战赛——完赛告捷！/1752587147944.png)

随后在线下进行决赛，最后斩获第八！！！  

2

这次比赛中，团队也有很多初入赛道的新师傅一起，在学习中比赛，得到了极大的提高。

![](/images/字节ByteAI安全挑战赛——完赛告捷！/1752587148041.png)

  

**01**

同时针对AI方面的测试，团队也会准备LLM安全的专题分享，时间为本周六晚，11月2号，具体参与时间与方式大家可以加入我们的QQ群获取实时通知。  
安全学习colab-3群：701604947

安全学习colab-4群：701934709

  

**大语言模型攻击手册**

  

**大语言模型prompt安全**

Prompt 注入攻击是伴随 LLM 技术发展所产生的新问题，被 OWASP 列为大语言模型应用漏洞 TOP 10
之首，意为通过设计过的输入操纵大语言模型，引发 LLM 做出预期之外的未授权行为。由于 LLM
集成应用模糊了数据和指令之间的界限，攻击者可以通过直接注入或间接注入，指示 LLM 返回敏感数据，操纵 LLM 的输出或是触发其他未授权的操作。

  

**《大语言模型Prompt攻击手册》**

由SecureNexusLab大语言模型（LLM）团队编写，基于广泛的文献研究、测试平台构建及开源模型测试等一系列工作，系统化地总结了针对 LLM
的攻击技术。您可以通过以下链接获取完整的《大语言模型提示攻击手册》PDF文件，欢迎star和关注~

* * *

https://github.com/SecureNexusLab/LLMPromptAttackGuide.git

  

团队往期直播视频  

【SecureNexusLab的个人空间-哔哩哔哩】

https://b23.tv/W7CWKjp

![](/images/字节ByteAI安全挑战赛——完赛告捷！/1752587148169.png)

团队也会不定期招收新成员，可以关注公众号或者QQ社群哦！

最后，希望大家可以在新的安全领域，斩获属于自己的成绩！

  

  

